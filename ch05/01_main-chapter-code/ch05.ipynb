{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
      "metadata": {
        "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
      },
      "source": [
        "# Chapter 5: Pretraining on Unlabeled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "92b989e9-da36-4159-b212-799184764dd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b989e9-da36-4159-b212-799184764dd9",
        "outputId": "3d1cb8ba-32b1-422d-9bdb-40c69e0d298d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "numpy version: 2.0.2\n",
            "tiktoken version: 0.11.0\n",
            "torch version: 2.6.0+cu124\n",
            "tensorflow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\" # For OpenAI's pretrained weights\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
        "# Source for \"Build a Large Language Model From Scratch\"\n",
        "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
        "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
        "#\n",
        "# This file collects all the relevant code that we covered thus far\n",
        "# throughout Chapters 2-4.\n",
        "# This file can be run as a standalone script.\n",
        "\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "#####################################\n",
        "# Chapter 2\n",
        "#####################################\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 3\n",
        "#####################################\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 4\n",
        "#####################################\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "_iyJy1lrdckH"
      },
      "id": "_iyJy1lrdckH",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "86000d74-624a-48f0-86da-f41926cb9e04",
      "metadata": {
        "id": "86000d74-624a-48f0-86da-f41926cb9e04"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# If the `previous_chapters.py` file is not available locally,\n",
        "# you can import it from the `llms-from-scratch` PyPI package.\n",
        "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
        "# E.g.,\n",
        "# from llms_from_scratch.ch04 import GPTModel\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();  # Disable dropout during inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
        "outputId": "6def574c-c5d8-40ff-f2b9-047517d39bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "# Alternatively:\n",
        "# from llms_from_scratch.ch04 import generate_text_simple\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
      "metadata": {
        "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98",
      "metadata": {
        "id": "0f3d7ea2-637f-4490-bc76-e361fc81ae98"
      },
      "source": [
        "### 5.1.2 Calculating the text generation loss: cross-entropy and perplexity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f",
      "metadata": {
        "id": "6b5402f8-ec0c-4a44-9892-18a97779ee4f"
      },
      "outputs": [],
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b6ec51-6f8c-49bd-a349-95ba38b46fb6",
        "outputId": "3a58800d-e8dd-4fe7-a190-30761de7db6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
        "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384d86a9-0013-476c-bb6b-274fd5f20b29",
      "metadata": {
        "id": "384d86a9-0013-476c-bb6b-274fd5f20b29"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-to-text.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ebd76a-16ec-4c17-8958-8a135735cc1c",
        "outputId": "b1224623-e69a-499d-95d4-55f41c65ea51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[16657],\n",
            "         [  339],\n",
            "         [42826]],\n",
            "\n",
            "        [[49906],\n",
            "         [29669],\n",
            "         [41751]]])\n"
          ]
        }
      ],
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c990ead6-53cd-49a7-a6d1-14d8c1518249",
        "outputId": "c80fedc4-fa2f-4616-8ad5-ddf7df7a9128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1:  Armed heNetflix\n"
          ]
        }
      ],
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e",
      "metadata": {
        "id": "ad90592f-0d5d-4ec8-9ff5-e7675beab10e"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/proba-index.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54aef09c-d6e3-4238-8653-b3a1b0a1077a",
        "outputId": "f4473671-5596-4a8c-846f-0c9f06b6a637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
            "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
          ]
        }
      ],
      "source": [
        "text_idx = 0\n",
        "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 1:\", target_probas_1)\n",
        "\n",
        "text_idx = 1\n",
        "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
        "print(\"Text 2:\", target_probas_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31402a67-a16e-4aeb-977e-70abb9c9949b",
        "outputId": "f222b4c9-e47c-4b54-cded-b0e9dce7235a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
          ]
        }
      ],
      "source": [
        "# Compute logarithm of all token probabilities\n",
        "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
        "print(log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9b003797-161b-4d98-81dc-e68320e09fec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b003797-161b-4d98-81dc-e68320e09fec",
        "outputId": "03ada654-8914-4c3d-f58d-88109e84de4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-10.7940)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average probability for each token\n",
        "avg_log_probas = torch.mean(log_probas)\n",
        "print(avg_log_probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "176ddf35-1c5f-4d7c-bf17-70f3e7069bd4",
        "outputId": "77f00530-22bb-4053-9d5c-42e99ac9c6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "neg_avg_log_probas = avg_log_probas * -1\n",
        "print(neg_avg_log_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54",
      "metadata": {
        "id": "5bd24b7f-b760-47ad-bc84-86d13794aa54"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/cross-entropy.webp?123\" width=400px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "695d6f64-5084-4c23-aea4-105c9e38cfe4",
        "outputId": "ac4e5030-81c7-4b01-d606-c714f42b89ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 3, 50257])\n",
            "Targets shape: torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e17e027-ab9f-4fb5-ac9b-a009b831c122",
        "outputId": "90455946-1ff4-4030-8b31-2ad5859f4217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flattened logits: torch.Size([6, 50257])\n",
            "Flattened targets: torch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62d0816e-b29a-4c8f-a9a5-a167562de978",
        "outputId": "ced86687-5b35-4e65-d290-e7d187a1376a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.7940)\n"
          ]
        }
      ],
      "source": [
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "168952a1-b964-4aa7-8e49-966fa26add54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "168952a1-b964-4aa7-8e49-966fa26add54",
        "outputId": "d913da40-7ab9-410c-eaaf-7947a08043ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(48725.8203)\n"
          ]
        }
      ],
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
      "metadata": {
        "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
      },
      "source": [
        "### 5.1.3 Calculating the training and validation set losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
      "metadata": {
        "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data = response.read().decode('utf-8')\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6kgJbe4ehI4q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kgJbe4ehI4q",
        "outputId": "08079582-0bf6-4588-e2af-f9ad2be00917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "# First 99 characters\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "j2XPde_ThM_e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2XPde_ThM_e",
        "outputId": "de9ca6df-b9cb-407c-d1f5-b3e02d2d2685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
          ]
        }
      ],
      "source": [
        "# Last 99 characters\n",
        "print(text_data[-99:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
        "outputId": "4044477f-994b-4379-ad83-f3aceeb78c53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
      "metadata": {
        "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/batching.webp\" width=500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0959c855-f860-4358-8b98-bc654f047578",
      "metadata": {
        "id": "0959c855-f860-4358-8b98-bc654f047578"
      },
      "outputs": [],
      "source": [
        "# Alternatively:\n",
        "# from llms_from_scratch.ch02 import create_dataloader_v1\n",
        "\n",
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e",
      "metadata": {
        "id": "f37b3eb0-854e-4895-9898-fa7d1e67566e"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "\n",
        "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the training loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"increase the `training_ratio`\")\n",
        "\n",
        "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
        "    print(\"Not enough tokens for the validation loader. \"\n",
        "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
        "          \"decrease the `training_ratio`\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
        "outputId": "43f11d93-fda2-46b0-c685-c8940c213aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "eb860488-5453-41d7-9870-23b723f742a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb860488-5453-41d7-9870-23b723f742a0",
        "outputId": "4b6426cb-1378-43ee-bf18-09f87845d861"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc",
      "metadata": {
        "id": "7b9de31e-4096-47b3-976d-b6d2fdce04bc"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
        "outputId": "46c99fe9-507b-4f50-e301-73f1aa6c3372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.987583266364204\n",
            "Validation loss: 10.981104850769043\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Note:\n",
        "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
        "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
        "# However, the resulting loss values may be slightly different.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#\n",
        "# print(f\"Using {device} device.\")\n",
        "\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43875e95-190f-4b17-8f9a-35034ba649ec",
      "metadata": {
        "id": "43875e95-190f-4b17-8f9a-35034ba649ec"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-1.webp\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
      "metadata": {
        "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
      },
      "source": [
        "## 5.2 Training an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
      "metadata": {
        "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
      },
      "source": [
        "- In this section, we finally implement the code for training the LLM\n",
        "- We focus on a simple training function (if you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code))\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=300px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "Mtp4gY0ZO-qq",
      "metadata": {
        "id": "Mtp4gY0ZO-qq"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
      "metadata": {
        "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
      },
      "source": [
        "- Now, let's train the LLM using the training function defined above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3422000b-7aa2-485b-92df-99372cd22311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3422000b-7aa2-485b-92df-99372cd22311",
        "outputId": "c257abbd-baaf-4ff8-b9e5-d79fdcdaee62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.930\n",
            "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.336\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.623, Val loss 7.053\n",
            "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.605\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.532, Val loss 6.507\n",
            "Ep 3 (Step 000025): Train loss 5.399, Val loss 6.389\n",
            "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
            "Ep 4 (Step 000030): Train loss 4.895, Val loss 6.280\n",
            "Ep 4 (Step 000035): Train loss 4.648, Val loss 6.304\n",
            "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 4.023, Val loss 6.165\n",
            "Every effort moves you know                                                 \n",
            "Ep 6 (Step 000045): Train loss 3.625, Val loss 6.172\n",
            "Ep 6 (Step 000050): Train loss 3.045, Val loss 6.144\n",
            "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
            "Ep 7 (Step 000055): Train loss 2.948, Val loss 6.183\n",
            "Ep 7 (Step 000060): Train loss 2.230, Val loss 6.128\n",
            "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
            "Ep 8 (Step 000065): Train loss 1.774, Val loss 6.162\n",
            "Ep 8 (Step 000070): Train loss 1.475, Val loss 6.229\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
            "Ep 9 (Step 000075): Train loss 1.135, Val loss 6.268\n",
            "Ep 9 (Step 000080): Train loss 0.858, Val loss 6.298\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
            "Ep 10 (Step 000085): Train loss 0.627, Val loss 6.382\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ],
      "source": [
        "# Note:\n",
        "# Uncomment the following code to calculate the execution time\n",
        "# import time\n",
        "# start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# Uncomment the following code to show the execution time\n",
        "# end_time = time.time()\n",
        "# execution_time_minutes = (end_time - start_time) / 60\n",
        "# print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0WSRu2i0iHJE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "0WSRu2i0iHJE",
        "outputId": "8a6d42e3-16d0-4239-eb70-752a1194f70b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
      "metadata": {
        "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
      },
      "source": [
        "- Looking at the results above, we can see that the model starts out generating incomprehensible strings of words, whereas towards the end, it's able to produce grammatically more or less correct sentences\n",
        "- However, based on the training and validation set losses, we can see that the model starts overfitting\n",
        "- If we were to check a few passages it writes towards the end, we would find that they are contained in the training set verbatim -- it simply memorizes the training data\n",
        "- Later, we will cover decoding strategies that can mitigate this memorization by a certain degree\n",
        "- Note that the overfitting here occurs because we have a very, very small training set, and we iterate over it so many times\n",
        "  - The LLM training here primarily serves educational purposes; we mainly want to see that the model can learn to produce coherent text\n",
        "  - Instead of spending weeks or months on training this model on vast amounts of expensive hardware, we load pretrained weights later"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb380c42-b31c-4ee1-b8b9-244094537272",
      "metadata": {
        "id": "eb380c42-b31c-4ee1-b8b9-244094537272"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-2.webp\" width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de713235-1561-467f-bf63-bf11ade383f0",
      "metadata": {
        "id": "de713235-1561-467f-bf63-bf11ade383f0"
      },
      "source": [
        "**If you are interested in augmenting this training function with more advanced techniques, such as learning rate warmup, cosine annealing, and gradient clipping, please refer to [Appendix D](../../appendix-D/01_main-chapter-code)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c",
      "metadata": {
        "id": "6d5cdf2f-09a5-4eb0-a20a-d7aac5c14c2c"
      },
      "source": [
        "**If you are interested in a larger training dataset and longer training run, see [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "699f45fc-bf78-42f2-bd24-2355db41b28f",
      "metadata": {
        "id": "699f45fc-bf78-42f2-bd24-2355db41b28f"
      },
      "source": [
        "## 5.3 Decoding strategies to control randomness"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7",
      "metadata": {
        "id": "6be9086e-2c27-41da-97d0-49137d0ba3c7"
      },
      "source": [
        "- Inference is relatively cheap with a relatively small LLM as the GPT model we trained above, so there's no need to use a GPU for it in case you used a GPU for training it above\n",
        "- Using the `generate_text_simple` function (from the previous chapter) that we used earlier inside the simple training function, we can generate new text one word (or token) at a time\n",
        "- As explained in section 5.1.2, the next generated token is the token corresponding to the largest probability score among all tokens in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
      "metadata": {
        "id": "2734cee0-f6f9-42d5-b71c-fa7e0ef28b6d",
        "outputId": "753ac746-5b32-4abf-8345-9b0233bb74f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
          ]
        }
      ],
      "source": [
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=25,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4",
      "metadata": {
        "id": "d25dbe31-bb7c-4893-b25b-47d0492d4aa4"
      },
      "source": [
        "- Even if we execute the `generate_text_simple` function above multiple times, the LLM will always generate the same outputs\n",
        "- We now introduce two concepts, so-called decoding strategies, to modify the `generate_text_simple`: *temperature scaling* and *top-k* sampling\n",
        "- These will allow the model to control the randomness and diversity of the generated text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994",
      "metadata": {
        "id": "4bb6f380-a798-4fd9-825c-17b7cd29a994"
      },
      "source": [
        "### 5.3.1 Temperature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa",
      "metadata": {
        "id": "a7f4f53c-0612-43d3-aa82-52447eac50fa"
      },
      "source": [
        "- Previously, we always sampled the token with the highest probability as the next token using `torch.argmax`\n",
        "- To add variety, we can sample the next token using The `torch.multinomial(probs, num_samples=1)`, sampling from a probability distribution\n",
        "- Here, each index's chance of being picked corresponds to its probability in the input tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7531bae-d5de-44c0-bc78-78fed077e22a",
      "metadata": {
        "id": "e7531bae-d5de-44c0-bc78-78fed077e22a"
      },
      "source": [
        "- Here's a little recap of generating the next token, assuming a very small vocabulary for illustration purposes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
      "metadata": {
        "id": "01a5ce39-3dc8-4c35-96bc-6410a1e42412",
        "outputId": "9561f5db-3ca0-4099-ae7b-f3b9843ba672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "vocab = {\n",
        "    \"closer\": 0,\n",
        "    \"every\": 1,\n",
        "    \"effort\": 2,\n",
        "    \"forward\": 3,\n",
        "    \"inches\": 4,\n",
        "    \"moves\": 5,\n",
        "    \"pizza\": 6,\n",
        "    \"toward\": 7,\n",
        "    \"you\": 8,\n",
        "}\n",
        "\n",
        "inverse_vocab = {v: k for k, v in vocab.items()}\n",
        "\n",
        "# Suppose input is \"every effort moves you\", and the LLM\n",
        "# returns the following logits for the next token:\n",
        "next_token_logits = torch.tensor(\n",
        "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
        ")\n",
        "\n",
        "probas = torch.softmax(next_token_logits, dim=0)\n",
        "next_token_id = torch.argmax(probas).item()\n",
        "\n",
        "# The next generated token is then as follows:\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
      "metadata": {
        "id": "6400572f-b3c8-49e2-95bc-433e55c5b3a1",
        "outputId": "61f53a4c-7ad7-4d5e-bcb4-c1f90faabedf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forward\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
        "print(inverse_vocab[next_token_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9",
      "metadata": {
        "id": "c63d0a27-830b-42b5-9986-6d1a7de04dd9"
      },
      "source": [
        "- Instead of determining the most likely token via `torch.argmax`, we use `torch.multinomial(probas, num_samples=1)` to determine the most likely token by sampling from the softmax distribution\n",
        "- For illustration purposes, let's see what happens when we sample the next token 1,000 times using the original softmax probabilities:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
      "metadata": {
        "id": "b23b863e-252a-403c-b5b1-62bc0a42319f",
        "outputId": "1874ded9-7871-470d-ff31-ca66d203d7e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "582 x forward\n",
            "2 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "343 x toward\n",
            "0 x you\n"
          ]
        }
      ],
      "source": [
        "def print_sampled_tokens(probas):\n",
        "    torch.manual_seed(123) # Manual seed for reproducibility\n",
        "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
        "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
        "    for i, freq in enumerate(sampled_ids):\n",
        "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
        "\n",
        "print_sampled_tokens(probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832",
      "metadata": {
        "id": "32e7d9cf-a26d-4d9a-8664-4af1efa73832"
      },
      "source": [
        "- We can control the distribution and selection process via a concept called temperature scaling\n",
        "- \"Temperature scaling\" is just a fancy word for dividing the logits by a number greater than 0\n",
        "- Temperatures greater than 1 will result in more uniformly distributed token probabilities after applying the softmax\n",
        "- Temperatures smaller than 1 will result in more confident (sharper or more peaky) distributions after applying the softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d2b5399",
      "metadata": {
        "id": "0d2b5399"
      },
      "source": [
        "- Note that the resulting dropout outputs may look different depending on your operating system; you can read more about this inconsistency [here on the PyTorch issue tracker](https://github.com/pytorch/pytorch/issues/121595)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d",
      "metadata": {
        "id": "0759e4c8-5362-467c-bec6-b0a19d1ba43d"
      },
      "outputs": [],
      "source": [
        "def softmax_with_temperature(logits, temperature):\n",
        "    scaled_logits = logits / temperature\n",
        "    return torch.softmax(scaled_logits, dim=0)\n",
        "\n",
        "# Temperature values\n",
        "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
        "\n",
        "# Calculate scaled probabilities\n",
        "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
      "metadata": {
        "id": "2e66e613-4aca-4296-a984-ddd0d80c6578",
        "outputId": "9be1d793-955e-497b-f807-0bcf5ff6e65f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPrBJREFUeJzt3QeUU9X2P/BNE6RJ7yBNQaRJBykqHRRBUZqAtCcCgiIoIFWqNIHHUKQJ0uUJKkoRnnSQXqQqRXj0jgICwv2v7/6tm38SMsPMJJmcm/l+1spi5s5Mcidksu85Z5+9E1iWZQkREREZKWGoT4CIiIgix0BNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBEks88+DBAzlz5oykSpVKEiRIEOrTISKieMiyLPnzzz8lW7ZskjBh1GPmeBeoEaRz5swZ6tMgIiKSU6dOSY4cOaL8nngXqDGStp+c1KlTh/p0iIgoHrpx44YOGu2YFJV4F6jt6W4EaQZqIiIKpegswTKZjIiIyGAhDdTr1q2TV155RRfTcVWxZMmSR/7MmjVrpESJEpI0aVLJnz+/fPnll3FyrkRERPEuUN+8eVOKFSsmERER0fr+48ePS926deXFF1+U3bt3y/vvvy9t27aVFStWBP1ciYiIQiGka9S1a9fWW3RNmjRJ8uTJI6NGjdLPn3nmGdmwYYN8/vnnUrNmzSCeKRHF9TbKu3fvhvo0iGItSZIkkihRIgkERyWTbd68WapVq+ZxDAEaI+vI3LlzR2/umXZEZC4EaMyeIVgTOVmaNGkkS5YsftfscFSgPnfunGTOnNnjGD5H8L19+7Y8/vjjD/3M0KFDZcCAAXF4lkTkTxGIs2fP6kgEW1ceVQiCyNTX8a1bt+TChQv6edasWeNPoI6Nnj17SteuXR/au0ZE5vnnn3/0DQ4JpsmTJw/16RDFmj1wRLDOlCmTX9PgjgrUmEI4f/68xzF8jv3QvkbTgOxw3IiM0v+JKL52XeKr+/fv67+PPfZYqE+FyG/2xea9e/f8CtSOmlcqX768rF692uPYTz/9pMeJKHywDj+FgwQBeh2HNFD/9ddfus0KN0ACCT4+efKka9q6RYsWru9v3769HDt2TD766CM5dOiQTJgwQRYuXCgffPBByH4HIiKiYAppoN6+fbs899xzegOsJePjvn376udIKrGDNmBr1g8//KCjaOy/xjatqVOncmsWERGFrZCuUb/wwguaHRcZX1XH8DO7du0K8pkRkUly9/ghTh/vxLC6AZve7Nevn/Tv31/CSe7cuXVbbFRbY03XuXNn2bhxo/z6669ak8Oe2TWRo5LJiIhMg5k/24IFC3RG8PDhw65jKVOmFCfAoAnJfIkTJ47TPfOhTBxs3bq1/PLLL7J3714xmaOSyYiITNyNYt+eeOIJHWG7H5s/f76O2JIlSyYFCxbU3BrbiRMn9PuRa1OpUiXdvVK6dGk5cuSIbNu2TUqVKqWBHhUcL1686Pq5t99+W+rXr681IjJmzKg7X5DD417NDQVjUEcCS4a4XywXLlq0yKNvAh572bJlUrJkSd0dg0qPR48elVdffVVrVOCxcT6rVq3ymNX8448/NDcIP2/PKGDWoHjx4h7PzZgxY3T07X3egwcP1i14BQoUcLUdfvPNN7VASLp06fTx8dwE07hx46Rjx46SN29eMR0DNRFRkMyZM0dH2AhMBw8elCFDhkifPn1k5syZD02P9+7dW3bu3Kkj2qZNm2rS7NixY2X9+vXy+++/u3J3bNgBg/tEwJ03b5588803HsWdEKRnzZqlpZf379+vgfWtt96StWvXetxPjx49ZNiwYXpfRYsW1STfOnXq6P1jmbFWrVraPMnOF8Lj5MiRQz799FOdTXCfUYgO3C9mHJBrtHTpUt26hDwj9GXG74rpaFwg4HGjKiObMmXKKG+4cAkXnPomIgoSBGAkvb722mv6OUa3Bw4ckMmTJ0vLli1d39etWzdXUmyXLl2kSZMmGtCef/55PdamTZuHcnYwZTx9+nTdq/vss89q4OzevbsMHDhQgx8uCjAStrevYuSIETMeu0qVKq77wc9Vr17d9TlGtBh923B/ixcvlu+++046deqkX8eeYARWzBjEVIoUKTQJ2J7ynj17to7+ccwenc+YMUNH17gIqVGjhs/7edSaMmYZwgUDNRFRkLoDYhoZQbZdu3Ye1dcwRe4OI1mbXSa5SJEiHsfscpQ2BFP36m0IyBgNYxoZ/6LCm3sABoxQ7V02Nkyvu8PPYhobO2wwWsb5okSz+w4cf+D3cl+X3rNnj84YIPC7+/vvv/X5iwzaHMcXDNREREGAgAdTpkyRsmXLenzNu0oVOi3Z7FGl97GYNCmxHxvBNnv27B5f867UiBGuO4zuMS09cuRIDYZY327YsOEju5mhLrv3Lh6M7L15Px7OFWvkWCbwhvX3yDwqSQ/T/Jj2DwcM1EREQYBRMBKmUKSpWbNmAb9/jETdmxFt2bJFgxd6GWB6GgEZo2D3ae7owBoxkr4aNGjgCqTeiV0YEdvlXt2DKhonIVjbFxvR2fJUokQJzZZHPeyYTFfv5tQ3ERH5C8ld2K+LqW4kR6HlLgo9Xb161aNZUGxghItpdSShIZBiPRxryBjZYhoZI2MkkGEkXrFiRbl+/boGYQQw9/Vxb0899ZQmjCGBDAEXyW/eo3lkcq9bt04aN26sFwQZMmTQbHBkpg8fPlxH4MuXL9eM8kcFTFzEjBgxQjO9sV6ORDVkleMckFCXI0eOoEx9Y7odFyG4uMAFjx34CxUqZFyteWZ9ExEFSdu2bTVJCslRWJvF6BZJYUgq81fVqlU1qFauXFkaNWok9erV8yisgiQwBFlkf2N7GC4UMBX+qMcePXq0pE2bVipUqKDBGkluGPW6Q0DFxUG+fPlc09N4DGw9i4iI0PXzrVu36sXCo2CdHUE/V65cmnSH+8EFCNaogzkqbtu2ra7XI7kO2+HsKplnzpwR0ySwoioNFobQ5hJXt7i6DKepEXIYds/yCW/OqPmPYIJ9x+QbpqavXbsmS5YsCfWpUCxfzzGJRRxRExERGYyBmoiIyGBMJiMichhfDYsofHFETUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1EZEfUA87qpt7Wc9wgVrfY8aMESc7efKk1K1bV0uYoiEIenmjpWdUBg8erKVV8TPolx1XuI+aiJxdcjUojxf9Mq7o2WxDF6i+ffvK4cOHo92O0RSoJo2OWIkTx11YQGORUDTAuH//vgbpLFmyyKZNm/T/sEWLFtpadMiQIVGe7xtvvKG9v6dNmxZn58sRNRGRH/Bmb99QuxmjaPdj8+fP10YTqPVcsGBBbVxhQ2MLfP/ChQulUqVK2rKydOnS2iRi27ZtUqpUKQ30tWvX1s5U7rW+69evr9250BQDtaLbt2/v0TMaHa/QkAN1pnG/aJSxaNEi19fXrFmjj40OV+gHjS5YGzZskKNHj2onK7TpxGPjfFatWuX6OXTJQncrdOayZw0AMwfFixf3eG4w6sbo2/u8MTJFC9ACBQro8VOnTsmbb76po1S06MTje7fWDKSVK1fKgQMHZPbs2XrOeH7RxAQNRaLqu43nG783GqzEJQZqIqIgmTNnjo6wEZgOHjyoozV0tJo5c6bH96FFJdpV7ty5U0e0TZs21RaPY8eOlfXr12tLRtyPu9WrV+t9IuDOmzdP20IikNgQpGfNmiWTJk2S/fv3a4B56623ZO3atR7306NHDxk2bJjeV9GiRbX1Y506dfT+d+3apV230EULU8WAx0HrSXTQwkjUfUYhOnC/mHH46aefZOnSpXLv3j3t0IXWnPhd0YoTFwh43KiCZsqUKaO84cIlMps3b9Zgi4sRG84BjTLwXJmGU99EREGCADxq1Cht3wgY3WIkh9aK7j2h0Q4SgQK6dOkiTZo00YD2/PPP6zG0ffQuG4op4+nTp+t66bPPPquBE+usGBki+OGiACNhTNNC3rx5dcSMx0a7TRt+rnr16q7PMaLF6NuG+1u8eLF899132u8aX0+UKJEGVswYxFSKFCm09ac95Y1RLUb/OGaPztEWFKNrXITUqFHD5/3Y/aMjE1VHKvSgdg/SYH+Or5mGgZqIKAhu3ryp08gIsu3atXMdR8ISpsjdYSTrHTDcp1dx7MKFCx4/g2CKIG1DQMZoGNPI+PfWrVseARgwQkXPZXeYXneHn8U0NnpXY7SM8719+7ZrRO0v/F7u69J79uzRGQMEfu8WkXj+IpM/f36JLxioiYiCAAEPpkyZImXLlvX4Gkak7pDEZLNHld7HMOqM6WMj2GbPnt3ja1iL9h7husPoHtPSI0eO1GCI9e2GDRtGOQ0NCRMm1IQ0dxjZe/N+PJwr1sixTOAN6++ReVSSHqb5Me3vC2YCtm7d6nHs/Pnzrq+ZhoGaiCgIMApGwtSxY8ekWbNmAb9/jEQx0kUghS1btmjwypkzp05PIyBjFOw+zR0dWCNG0leDBg1cgdQ7sQsjYmROewdVTBsjWNsXG4+anoYSJUpotjy2SEU1XR3IqW/MPiBvALMUeFzAxQl+plChQmIaBmoioiBBclfnzp11qhvJUXfu3JHt27fL1atXpWvXrn7dN0a4mFZHEhoCKdbDsYaMkS2mkTEyRgIZRuIVK1aU69evaxBGMHJfH/f21FNPacIYEsgQcJH85j2aRyb3unXrpHHjxnpBkCFDBs0GR2b68OHDdQS+fPlyzSh/VPDFRcyIESM00xvr5UhUQ1Y5zgEJdTly5Aj41DfWvRGQmzdvrueLCww8jx07dnTNOGDEjS1byBWwZyVw4XPlyhX9Fxcq9sUCziWY2/BCnvWNdHj8p2PrAqaHvKcjvCHdHyn9uIrElSNeiFjLICIyTdu2bTVJCslRWJvF6BZJYUgq81fVqlU1qFauXFkaNWok9erV8yiugiQwBFlkf2N7GC4UMBX+qMcePXq0pE2bVgt7IFgjyQ2jXncIqLg4yJcvn2t6Go+BrWd4T8f6Od7LcbHwKFhnR9DPlSuXJt3hfnABgvf1mIywYwJLD8g4x78YXWOaHEEZv5cNa/zITnefvkfmPdb4cVGEmQZ8jBsuvoIpgeW9qBCHMN2BJwfrCAjSCMJff/21Pjn2dIS7uXPnSuvWrTXTES8i7DXEFA2u6vDiig6k3+PqFleXwXoREPlVwCMGxTbCDd6cjx8/rsEEF+/kG973rl27JkuWLAn1qVAsX88xiUUhHVEjuCIbslWrVjoNgYCNqysEYl9QQQbbFbDHEKNwTF9gG8OjRuFEREROFbJAjfWVHTt2SLVq1f7/ySRMqJ9jM7ovGEXjZ+zAjCSNH3/8UTfnExERhaOQJZNdunRJF+N9bTo/dOiQz5/BSBo/h8QIzNhjfx+qz/Tq1SvSx0HyBm7u0w1ERE7mXfyEwlvIk8liAlVqUG0HCQsotYesQCRHIGkiMkikwDqAfUMCGhERkVOEbESNdH5k3NmbzG34PLIN58hgRDo9MikBWZSo/vOvf/1LPvnkE50699azZ0+PbRAYUTNYExGRU4RsRI0N86hGgz1qNuzVw+d2bVpvSJf3DsZ2hZ/IktexJw4Zde43IiIipwhpwROMdLHxHrVmy5Qpo9uzMEJGFjhg6xY2mmP6GrCnD5ni2LeG7VyoD4tRNo57l+QjIiIKByEN1Nikj0o22ESOyjDoC4pqNnaCGaq/uI+gUTkGlXLw7+nTp3WjPYI0SsERERGFo5AWPAkFFjwhI7DgiU8seELh5O9wKHhCREREUWOgJiLyA5bjorq5198OF6gMiZwiJ0vg4/9q/vz5YiJ2zyIi4xWZWSROH29fy33R/t6zZ8969C9Azg36FdiC2VUpkLAKiiJUiRMnjtMKldgBFCozZszQZiW2NGnSiIk4oiYi8gPqPtg3rDliZOZ+DKM0dITCGmXBggW1YJMNHajw/QsXLpRKlSppV8DSpUtrw6Ft27bpjhgE+tq1a2virXtTjvr162sbTSTVYo0TVRoR+Ny3u2LHDNZHcb/oaLVo0SKPAlJ4bLSixFZZbGXdsGGDHD16VFtOIqkXj43zWbVqlevn0M4SbSjRudAeiQJmDpAQ7A6jboy+vc8bCcDo1Y1OiHDq1Cl58803NVCilzYe37sHdjDg8dz/r0zNi2CgJiIKkjlz5ugIG4Hp4MGDWlkRW0pnzpzp8X1om4jdLKi4iBEtyiWjF/PYsWNl/fr1uhUV9+MONSdwnwi48+bN00qNCNw2BOlZs2Zps6P9+/drYEU7x7Vr13rcT48ePWTYsGF6X0WLFtX2jeifgPvftWuXjjixuwa7cACPgx7RaAmJ2QT3GYXowP1ixuGnn37SVpNoI4lWmuihjd8VPbNxgYDHdb/w8IbvieqGC5dHQf9pFN/C9mA0gzI1t5pT30REQYIAPGrUKO2zDBjdHjhwQCZPnqw1JGzo24xgBV26dNGugAho6BYI6M/sXd8bU8YILug4+Oyzz2rg7N69u5ZURvDDRQFGwnYBqbx58+qIGY+Nvtg2/Fz16tVdn2NEi9G3Dfe3ePFi+e6776RTp076ddStQGCNrIpkVFKkSKE9uu0p79mzZ+voH8fs0TmmpDHaxUVIjRo1fN7P7t27o3ycR2VS4/d+6aWX9PlbuXKldOjQQS9SOnfuLKZhoCYiCgIUb8I0MoIs2vna0EwIU+TuMJK12XUkUCLZ/diFCxc8fgbBFEHGhoCMQINpZPyLSo7uARgwQkXBKHeYXneHn8U0NvooYLSM8719+7ZrRO0v/F7u69J79uzRGQMEfu+tTXj+IpM/f37xB2Y2bHhO8P81YsQIBmoiovgCAQ+mTJmilRTdeVdSTJIkietje1TpfQyjzpg+NoItqju6w1q09wjXHUb3mJYeOXKkBkOsbzds2DDKaWhAcSrvqWOM7L15Px7OFWvkWCbwhvX3yDwqSQ/T/Jj2jy78H2H2AN0WvZ+jUGOgJiIKAoyCkTB17NgxadasWcDvHyNRjHQRSGHLli0avNB0CNPTCDYYBbtPc0cH1oiR9NWgQQNXIPVO7MKIGBni3kEVFSYRrO2LjUdNT0OJEiU0Wz5TpkwxKkK128+pb1/3lzZtWuOCNDBQExEFCZK7MJWKqW4kR2G0tn37drl69apHV7/YwAgX0+pIQkMgxXo41pAxssU0MkbGSCDDSLxixYpaAQtBGAHMfX3c21NPPaUJY0ggQ8DFFLH3aB6Z3OvWrZPGjRtrYENCFrLBkZk+fPhwHYGjHDQyyh8VMHERgylnZHpj3RiJasgqxzkgoS5HjhwBn/r+/vvvtVNjuXLlNNMbMwhY08dzZiJmfRMRBQla8iJJCslRWJvF6BZJYUgq81fVqlU1qFauXFn7JtSrV8+juAqmcRFkkf2N7WG4UMBU+KMeG42PMLKsUKGCBmskuWHU6w4BFRcH+fLlc01P4zGw9SwiIkLXz7du3RqtwId1dgT9XLlyadId7gcXIFijDlaZ5yRJkuh5Yl0fW8qQYIffGxc7JmKtb6JQYK1vn1jrO3owNX3t2jVZsmRJqE+FosBa30RERPEAAzUREZHBmExGROQw3sVPKLzFakT9888/B/5MiIiIKDCBGtmDyPYbNGiQVsEhIiIigwL16dOndb8eOrGgfizS99H95VGVa4iIoiOebUahMGUF6HUcq0CNze3YSI9KLr/88os8/fTTWtAcVXiwuR8Vc4iIYsourcmLfgoHt27deqgcbEiSybARHh1U0qdPr63S0M0Fm96xkRx1VtHVhYgoOtDiEQUwUOEKb26oskXkxJE0gjQaqaALmHdt9zgL1Ci2/u2332pgRvk1dGAZP368tmfDHxnK2r3xxhva0o2IKDpQsjJr1qxaJAJlJImcDEE6Nq1AAxKo33vvPW1UjquG5s2ba23XwoULe3RHQecVTIUTEcUEGj6gNCanv8nJkiRJ4vdI2q9AjVHyv//9b63LGlmnEaxjcxsXEcUGprxZQpTo/8RqAQiFyzGt7R2k0WAcxdXttaaYtlcjIiKiAATqF198Ua5cufLQcRQXx9eIiIgohIHavTG4u8uXL+v6NBEREUncr1FjTRoQpNFmzX3q+/79+7J3717tYUpEREQhCNTonWmPqFOlSiWPP/64R6ZmuXLlpF27dgE6NSIiIopRoJ4xY4b+mzt3bunWrRunuYmIiEzN+g5UkI6IiNDAj60YZcuWla1bt0b5/deuXZOOHTtqUQRMvaN86Y8//hiQcyEiInLsiBqlQlevXi1p06aV5557zmcymW3nzp3Rus8FCxZI165dtdQogvSYMWO0wcfhw4clU6ZMD30/CiBUr15dv4aGINmzZ9fqRaj+QkREFK8D9auvvupKHqtfv35AHnz06NG6pt2qVSv9HAH7hx9+0LKkPXr0eOj7cRzbwjZt2uQqco7ROBERUbhKYIWonxxGxyi+j5Gxe+Bv2bKlTm+jjri3OnXqSLp06fTn8PWMGTNK06ZN5eOPP460VNudO3f0Zrtx44bkzJlT93ynTp06SL8d0SP0fyKKr12PyzMhohBALEKCdnRiUcha01y6dEm3dGXOnNnjOD4/d+6cz585duyYBnb8HNal+/TpI6NGjZJBgwZF+jhDhw7VJ8O+IUgTERGF3dQ31qajWpd256tqWSA8ePBA16e/+OILHUGXLFlSTp8+LSNGjNAEN1969uyp6+DeI2oiIqKwCtRI9AokNO1AsD1//rzHcXweWVswZHp7dyR55plndASOqXTs5faGdfXIGocQERGFTaDG2nEgIahiRIxMcnuNGiNmfN6pUyefP/P888/L3Llz9fvshvJHjhzRAO4rSBMRETldtNeoMWXs/nFUt+jClPSUKVNk5syZcvDgQXn33Xfl5s2brizwFi1a6NS1DV/HtHqXLl00QCNDfMiQIbqvmoiISOL7GvXZs2d1jRj7ln2tV9vNOpDsFR2NGjWSixcvSt++fXX6unjx4rJ8+XJXgtnJkyddI2fA2vKKFSvkgw8+kKJFi+o+agRtZH0TERHF6+1Za9eu1aln9JnGx1ExuQ91TFLiifyRu8cPkX7tRLKmkf8gt2cRhb0bMYhF0R5RuwdfkwMxERFRvG3K4e7q1asybdo0XVuGQoUK6doyCpIQERFRYMSq4Mm6deu0dOe4ceM0YOOGj/PkyaNfIyIiohCOqJFljUSwiRMnuvY0I4GsQ4cO+rV9+/YF6PSIiIjit1iNqH///Xf58MMPPQqP4GNst8LXiIiIKISBGi0v7bVpdzhWrFixQJwXERERxWTqe+/eva6PO3furPuXMXouV66cHtuyZYtERETIsGHDgnOmRERE8VC091Gj8AiKmTzq22NS8CQUuI+a4gr3URNRnO6jPn78eHS/lYiIiAIk2oH6ySefDNRjEhERUbALnsCBAwe0HjdaTLqrV6+eP3dLRERE/gTqY8eOSYMGDXS/tPu6td2ow+Q1aiIiorDfnoWMb1Qhu3DhgiRPnlz279+vFclKlSola9asCfxZEhERxVOxGlFv3rxZ/vvf/0qGDBk0Gxy3ihUrytChQ3Xr1q5duwJ/pkRERPFQrEbUmNpOlSqVfoxgfebMGVfC2eHDhwN7hkRERPFYrEbUhQsXlj179uj0d9myZWX48OHy2GOPyRdffCF58+YN/FkSERHFU7EK1L1795abN2/qx59++qm8/PLLUqlSJUmfPr0sWLAg0OdIREQUb8UqUNesWdP1cf78+eXQoUNy5coVSZs2rSvzm4iIiEK8jxpOnTql/+bMmTMAp0NERER+J5P9888/0qdPH61Tmjt3br3hY0yJ37t3LzZ3SURERIEaUb/33nvyzTffaBJZ+fLlXVu2+vfvL5cvX5aJEyfG5m6JiIgoEIF67ty5Mn/+fKldu7brWNGiRXX6u0mTJgzUREREoZz6Tpo0qU53e8N2LWzTIiIiohAG6k6dOsnAgQPlzp07rmP4ePDgwfo1IiIiiuOp79dee83j81WrVkmOHDmkWLFi+jkKoKCLVtWqVQN0akRERBTtQI2sbnevv/66x+fcnkVERBTCQD1jxowgPDwREREFreDJxYsXXU04ChQoIBkzZvTn7oiIiCgQyWSo8926dWvJmjWrVK5cWW/ZsmWTNm3ayK1bt2Jzl0RERBSoQN21a1dZu3atfP/993Lt2jW9ffvtt3rsww8/jPH9RURE6HavZMmSaTeurVu3RuvnsJcbtcXr168fi9+CiIgoTAP1f/7zH5k2bZoWPEmdOrXe6tSpI1OmTJFFixbF6L7QbQuBv1+/frJz507NIkfTjwsXLkT5cydOnJBu3bpp1y4iIqJwFatAjentzJkzP3Q8U6ZMMZ76Hj16tLRr105atWolhQoVkkmTJkny5Mll+vTpkf7M/fv3pVmzZjJgwAD2vyYiorAWq0CN+t4YAf/999+uY7dv39bAadf+jg7su96xY4dUq1bt/59QwoT6OWqHRwY9sHFRgDXxR0Ehlhs3bnjciIiIwjrre8yYMVKrVq2HCp5gjXnFihXRvp9Lly7p6Nh7dI7P0ePalw0bNui0++7du6P1GEOHDtULCCIiongTqIsUKSK//fabzJkzxxVQ0YwD09GPP/64BMuff/4pzZs317XwDBkyROtnevbsqWvgNoyoWZyFiIjCNlCj33TBggVl6dKlurbsDwTbRIkSyfnz5z2O4/MsWbI89P1Hjx7VJLJXXnnFdezBgwf6b+LEiXVPd758+R5qIIIbERFRvFijTpIkicfatD/QaatkyZKyevVqj8CLz32tdeMCYd++fTrtbd/q1asnL774on7MkTIREYWbWE19d+zYUT777DOZOnWqjmT9gWnpli1bSqlSpaRMmTK6/o2CKsgChxYtWkj27Nl1rRlr4IULF/b4+TRp0ui/3seJiIjCQayi7LZt23TUu3LlSl2vTpEihcfXv/nmm2jfV6NGjbQUad++feXcuXNSvHhxWb58uSvB7OTJk5oJTkREFB/FKlBjFOvdPcsf6GEdWR/rNWvWRPmzX375ZcDOg4iIyNGBGuvHI0aMkCNHjuge6Jdeekn69+8f1ExvIiKi+CxGc8qDBw+WXr16ScqUKXXdeNy4cbpeTURERAaMqGfNmiUTJkyQd955Rz9ftWqV1K1bV5PKuI5MRBTecvf4wefxE8Pqxvm5xCcxiq5I7ELzDRtKfaJ71ZkzZ4JxbkRERPFejAL1P//8o1ukvPdVowgKERERhXjq27Isefvttz0qfaH4Sfv27T22aMVkexYREREFKFCjMIm3t956KyZ3QURERMEK1DNmzIjJtxMREZGfmKpNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBGKiJiIgMxkBNRERkMAZqIiIigzFQExERGYyBmoiIyGAM1ERERAZjoCYiIjIYAzUREZHBGKiJiIgMxkBNRERksMShPgEi8lRkZpFIv7av5b44PRciCj2OqImIiAzGQE1ERGQwIwJ1RESE5M6dW5IlSyZly5aVrVu3Rvq9U6ZMkUqVKknatGn1Vq1atSi/n4iIyMlCvka9YMEC6dq1q0yaNEmD9JgxY6RmzZpy+PBhyZQp00Pfv2bNGmnSpIlUqFBBA/tnn30mNWrUkP3790v27NlD8jsQEZFvzLkIgxH16NGjpV27dtKqVSspVKiQBuzkyZPL9OnTfX7/nDlzpEOHDlK8eHEpWLCgTJ06VR48eCCrV6+O83MnIiIK60B99+5d2bFjh05fu04oYUL9fPPmzdG6j1u3bsm9e/ckXbp0QTxTIiKieDj1fenSJbl//75kzpzZ4zg+P3ToULTu4+OPP5Zs2bJ5BHt3d+7c0Zvtxo0bfp41ERFRPJr69sewYcNk/vz5snjxYl2v9mXo0KHyxBNPuG45c+aM8/MkIiJyZKDOkCGDJEqUSM6fP+9xHJ9nyZIlyp8dOXKkBuqVK1dK0aJFI/2+nj17yvXr1123U6dOBez8iYiIwjpQP/bYY1KyZEmPRDA7Max8+fKR/tzw4cNl4MCBsnz5cilVqlSUj5E0aVJJnTq1x42IiMgpQr49C1uzWrZsqQG3TJkyuj3r5s2bmgUOLVq00G1XmMIGbMfq27evzJ07V/denzt3To+nTJlSb0REROEk5IG6UaNGcvHiRQ2+CLrYdoWRsp1gdvLkSc0Et02cOFGzxRs2bOhxP/369ZP+/fvH+fkTERGFdaCGTp066c0XFDhxd+LEiTg6KyIiotBzdNY3ERFRuGOgJiIiMhgDNRERkcGMWKOOj1ionoiIooMjaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiIyGAM1ERGRwRioiYiIDMZATUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY1MOIvIbm8xQOCli2OuZI2oiIiKDMVATEREZjFPf5NjpICKi+IAjaiIiIoMxUBMRERmMU99+yt3jh0i/dmJY3Tg9FyIiCj8cURMRERmMgZqIiMhgnPqmsMZMdQqn14YTz5n8xxE1ERGRwRioiYiIDMZATUREZDAjAnVERITkzp1bkiVLJmXLlpWtW7dG+f1ff/21FCxYUL+/SJEi8uOPP8bZuRIREcWrQL1gwQLp2rWr9OvXT3bu3CnFihWTmjVryoULF3x+/6ZNm6RJkybSpk0b2bVrl9SvX19vv/76a5yfOxERUdgH6tGjR0u7du2kVatWUqhQIZk0aZIkT55cpk+f7vP7x44dK7Vq1ZLu3bvLM888IwMHDpQSJUrI+PHj4/zciYiIwnp71t27d2XHjh3Ss2dP17GECRNKtWrVZPPmzT5/BscxAneHEfiSJUuCfr5ERORD/yci/1qeXHF5JmEppIH60qVLcv/+fcmcObPHcXx+6NAhnz9z7tw5n9+P477cuXNHb7br16/rvzdu3AjAbyDy4M6tSL8W1WPcv30/Vj8XCIX7rYj0a78OqGnkOcdWKM85ytdGAsvY5zmy1wdfG6EX6nOO7DXN13PM2fdjWZE/dy5WCJ0+fRpnaG3atMnjePfu3a0yZcr4/JkkSZJYc+fO9TgWERFhZcqUyef39+vXTx+DN95444033sSw26lTpx4ZK0M6os6QIYMkSpRIzp8/73Ecn2fJksXnz+B4TL4f0+ruU+UPHjyQK1euSPr06SVBggQSSLhCypkzp5w6dUpSp04tTsBzjhs857jBc44bPGf/YST9559/SrZs2R75vSEN1I899piULFlSVq9erZnbdiDF5506dfL5M+XLl9evv//++65jP/30kx73JWnSpHpzlyZNGgkmvAhMeCHEBM85bvCc4wbPOW7wnP3zxBNRrO2bVOsbo92WLVtKqVKlpEyZMjJmzBi5efOmZoFDixYtJHv27DJ06FD9vEuXLlKlShUZNWqU1K1bV+bPny/bt2+XL774IsS/CRERUeCFPFA3atRILl68KH379tWEsOLFi8vy5ctdCWMnT57UTHBbhQoVZO7cudK7d2/p1auXPPXUU5rxXbhw4RD+FkRERGEaqAHT3JFNda9Zs+ahY2+88YbeTIMpdhRu8Z5qNxnPOW7wnOMGzzlu8JzjVgJklMXxYxIREZFTKpMRERFR5BioiYiIDMZATUREZDAGaiIiIoMxUMfSP//8I7NmzXqoShoREVEgMevbD2jHefDgQXnyySfFKVBcBr28K1euLE6SN29e2bZtm5Z+dXft2jVtc3rs2DEJte+++y7a31uvXr2gnkt8hkY/+/bt07/LtGnThvp0HCsmzSdMqfTlbd26dRIVp7wPGrGP2qlQSW337t2OCtToHoY2ojhnVH9D4EblN9OdOHFC34C9oTPa6dOnxQR2GVwbasm7Xwe715b39buYYObMmVqDH1X/4KOPPtKqf+gVP2/ePCNf6ygnXKRIEb0AxfOKyoWbNm3SC+mlS5fKCy+8EOpTdCSUWo5uPwRTX88v+Pi/d8LfoTcGaj906NBBS6CiyDtqlqdIkcLj60WLFhXToIobKsF99dVX+qaMAgAI3HiTe/XVVyVJkiRiEvdR6ooVKzxq4+KPDHXfc+fOLSZAnXrbqlWr5OOPP5YhQ4a46tCjlzoq6uGYqXBuEydOdJ1vRESEfP755xrwPvjgA/nmm2/ENIsWLZK33npLP/7+++/l+PHj2iYXr/FPPvlENm7cKCbCeS9cuFCrL969e9fjazt37pRQ+/nnnz0ulHv06CFvv/22x+sZ7yF2eWcTXb161ePze/fuya5du6RPnz4yePBgcYwYdKUkLwkSJHjoljBhQte/TrBjxw6rU6dOVrJkyawMGTJY77//vnXkyBHL5OfYvj322GPW008/bX3//feWaZ599llr/fr1Dx1ft26dVbBgQctUjz/+uPXHH3/oxx999JHVvHlz/fjXX3/V14eJkiZN6moV2K5dO6tLly768bFjx6xUqVJZJho7dqyVMmVK/dvD6/idd96xqlWrZj3xxBNWr169LNO89NJLD7UXhjlz5lhVqlSxnGbNmjVWiRIlLKdgMpkfcOXufcNaqf2v6c6ePaudx3BDu9E6dero2h6mOTGKMmWUihumXDETYH+OG6a9Dx8+LC+//LKY5ujRoz67tGFGAKMTU6VMmVIuX76sH69cuVKqV6+uHydLlkxu374tJkJfgAMHDugMC/oE2Od869YtfV2baMKECbqk8O9//1u7CGKJAX+HnTt31uUp02D0jMZJ3nBs69at4jSZM2fW9w7HCPWVAsWtu3fvWosWLbLq1q1rJUmSxCpZsqQ1ceJE6/r1667v+eabb6w0adJYJp0zruhNGuk/SqVKlazq1atb586dcx3DxzVq1LAqV65smapp06Y60mjTpo2VPHly69KlS3r822+/1VkCE/Xr109HopipyJUrl/X333/r8WnTplnlypWzTJ25OHHihH6cMWNGa/fu3foxXuPp0qWzTIOZq+7duz90HMfwNVPt2bPH44bnedmyZToL8Pzzz1tOwTVqP2EdbNKkSTqKxlUnRn5o1ZknTx5d8zVN1qxZdTTapEkTvRJGtzJvL774YtB7dscE1s337t0rTjJt2jR57bXXJFeuXNqsHpDLYHd7MxXWpLGOjnP9z3/+48qy37Fjh75mTNS/f3/tnodzRrMeu+kCRtNYVzVRlixZ5MqVK/p+gdfIli1bpFixYvo+YuJGHMywvf7667Js2TIpW7asHsP7x2+//aavE1MVL178oaROKFeunEyfPl2cgtuz/ICkG7TnRNYpEhN+/fVX3Ub05ZdfapKFezKGSRcWeDPDVKaTIJEJb8DDhg0Tp8CfFqYzkdgEzzzzjCbuRTeTlmLu77//dsRru23btnoBh2ROXBx1795dnn/+edm+fbte4OFCzzT/+9//9D0PW1Lt13P79u1dF6Im+uOPPzw+R8vkjBkzOuI14o6B2g9Yy0WWLLblpEqVSvbs2aOBGgEb2wIuXbokJkHG4+OPP65bypzWv/u9997TAjMYkfrKsB89erSYwsnPM6xfv14mT56seRZff/21bt/DBR5miSpWrCimwdo0/g4xs4UCREeOHNG/Q2T2YkcAdjSYxs6zSJz4/yY158+fr1vK8Pp+5513dN3apNdzrVq19PnF+VHcYzKZHzBN9dxzzz10HCO/mzdvimkwhYxpNqfsHXSHix8UNsEFEd6IscXCviEgmsTJzzOmMWvWrKkXGtgihIQ9QIKTqdvKMJuFWazhw4d7BDhcJE2dOlVMhJGdHaShcePGMm7cOL0gNSlIO3Xpyd3atWvllVdekfz58+sNxYZwMeoooV4kd7JnnnnGWrJkiX6MrRZHjx7Vj8eNG2c999xzlommTp1q1alTx7p8+XKoTyWsOfV5Ll68uDVz5syHXtM7d+60MmfObJkoX7581qpVqx4654MHDxqVFOkuT5481ttvv+1KfLNdvHhRv2YabNv8+OOPLaf56quvrMSJE1tvvvmmbonDDR8jkRZby5yCyWR+QLGTjh076roYVhCQXIHqTSgAYOqV/Pjx4+X333+XbNmyaSKL9xSyCYUWorNWBjly5BBTOfV5xpYVX2UVsa0M5VpNhMp0GCl5w9Qypm1NhC16GFFXqlRJi/oguQwwC+O9rmpKbwMkX6GQj+lLT96zLZhpQY6LDVvgcL4DBw6Upk2bihMwUPuZEIIpQmTJYs8m/tPxxjx27FidyjKRd5lLp8Cb7qBBg2TUqFHy119/6TFMg3/44YdafQpTiSZx6vOMgIELDO9qbxs2bNB1X1NzRTCV6V3eFJW/fC1NmQAJhdjz3a1bNw182AlQunRpMX3pCbD05M7k5Mhjx47ptLc3TH/36tVLHCPUQ/pwcfPmTev8+fOhPo2w1aNHD91vOmHCBNeeyIiICD1mYiUnpxoyZIhVqFAha8uWLVrVC9XVZs+erc8zlnRMhOUn7KMeNmyY7v0eMWKE1bZtW634tXLlSstEqKxnv1/gtY191ZimxV57p1Q1dIJ8+fJZkyZNeug4akfkz5/fcgoGaj/cunVLA7QNBQw+//xza8WKFZbJrl69ak2ZMkXfIOw1VJQS/d///meZKmvWrFp0w9ebdLZs2UJyTuHowYMH1qBBg6wUKVK4SrWivGzv3r0tk6E0K0pw4oICQQ/FLEz+O0Qwdr+wR5DG89yqVSsG6gCaMGGCXrC1b9/emjVrlt5QrhVlZ30FcFNxe5YfatSooXsesZcQ63cFChTQjE1sy8IayLvvviumQfYm9vLapSyxJokpTUzfozkAtkCZCPsece5PP/20x3GcP4oamFbeEmuNKBIRWdMFFLswGc4XU+BYZsDUMkqLUuBgqebcuXOSKVMm1zEUTGrQoIGWyjVxxwD2eEf2ejaxWYtt8eLFumTmvv8b+9ZNLEgVqVBfKThZ+vTptVkBYIRatGhR6/79+9bChQuNbbxQtWpVVylA9wzZjRs3Wk8++aRlqjJlyljvvffeQ8fR1KBs2bKWafr06aOzACNHjtSR0sCBA7UsJ14zyDylwMHz+vPPP1vhAFPfaBhhmnnz5mmm9Msvv6wjVPyL0qFYckD2uqlatGhhrV271nI6BuoAdRp64403rP79++vHJ0+e1K+ZKHXq1Nbvv//+UKDGtD2mg0yFNy9Mx2JLXOvWrfWGj/E7YNrTNHnz5rWWLl2qH+Mc7eccQbpJkyaWqf766y+d5i5fvryu72GrkPvNRPXq1dPXbo4cOaxu3bpZu3btskw3YMAAa/Xq1T6ff3zNNEWKFLHGjx/v8b6BZRJ0K+vbt69lqldffVUvMLAePXjwYOv06dOWEzFQ+/nixRsvAjMC4KZNm/T49u3bjd1zijU87In1DtRIusEbncnwR4bEsddee01vn3zyibF/eEhqsi/ismTJojkAgOcbrxVTNW7cWGcC0OIS+RZjxozxuJnqypUr1uTJk7XZAtZ4kRCHN+bjx49bJrLbtI4aNcrjuKnJZHg9288lmobs3btXPz5w4IC+vk124cIFfZ4x44k91bVq1dJZTzT7cQoGaj98/fXXerWGPywksrhnzuLFYOo0Yf369fVFikCNnr0IKCjQYvfxNUWDBg1cXb1QhMO7OITJMC2IzGlAYtPQoUP14/nz5+vFkqkwlblhwwbLydCbevjw4br8lChRIsvUQI3XApZCMHV8584dowN19uzZXcEZAxS7NzUGJyZfeHrDBTOWy7Achf7qKOTihK58DNR+Onv2rI5QsTZt++WXX7QqkomuXbumFxWo2IQ3sZw5c+rFBlovYtrNJDivM2fO+MySNR2qOGFEB3hDxpU8pt8wijK5wlPu3Ll1lORUuABdvHix9frrr+ubsak7AuztWVgSwRIOlhrwuamBGss19uj/008/1YtNbIFDXgsuqJ3gzJkzuoWvQIECuoyG9Wvk7OBvc/To0ZbJmPUdj6pleRewQBY1snpRyACZ4KYpWrSonhvabrZq1UprIadOndrn97Zo0UJMhjaGdtMFXwUYTDF79mz59ttvtftb8uTJxSnQqW7u3LlaqxzFcbAbo1mzZvLSSy8ZWZADLTjPnj2rWd83btyQN998U/bv36+NL1CMw7Ssb+xSQAVGFHTC84tqX/brGTtG0qZNKya6d++eVn6bMWOGrFy5Ut9TUKgKxans9xJkhbdu3VquXr0qpmKgjkfVsgA9e01uS+du48aN+lwePXpU3yjw3Pp608Ux07c7mQzVu9yfV2zLwtsCqpOhIYPppU/R3Qv//+jwhOCMCyG7J7VTtmfhvQTtctFGEh+bFqidKkOGDPp8opd6u3btdCunN2ytxd8AmiyZiiVE/YBgjL6x6JGMXrL2SBWN7HH1iTqzpsGbL1oVvvXWW9KwYUNjr4QBzylGovYbG0oXuu87NRm6Z6HVaZUqVfTffPnyiamcWu7Uhr839FhPkyaNOAVGeKhlYMPrGzNGCBjr1q0T02DGCjNbqANv8mvZG2oZ4LURVf9pvG5MDtLAEbUfMA1kT1W5w9Rhhw4dtFmAadAWElOE6H+LwgoYhSBomzgKwfQl2hdiigpTsZgeRG11J8AUMt5w16xZoyNUjPoQtO3Azb6+weG0JSinwHQxXs/ur2X7QpSv5eBjoI5H1bLc4b8dQcR7XQ8dckyBKm/oJJQ1a1aPNT2nwXmjJ+7SpUtlwYIFRk9tbtu2Tc+vbNmyHsd/+eUX/T8oVaqUmMYpS1AYMf/rX//S9w18HBksQ6AvtYkw+EDAxusZN8xy4e/TvkCi4GCg9gPezHDz/qPDHxne8OxpW9Nh3bFNmzZ60WFSAHF6Mhk6qmEpBBdESHbCbAbKF2Ikgik5E5UpU0Y++ugjXRbxLhH52WefacA2Tc+ePXUJasCAAQ8tQWFd0pQlqDx58mgZzvTp0+vHUQVqdH0ykf2axusZr2u8d6DELF7bFDwM1H7AFWXdunV1PbJ8+fKuer1I2Prxxx+116ypcAWM0TRuaGGH80ciDuqWmwJZpej57cRksgoVKngEZkwRYn3P5JwAQE1vXLB5t7TEGh4unP78808xjROXoNzZb8EmZqfb0BISgdl+TdtT3054TYcDBmo/nTlzRiIiIuTQoUP6OV7EeHPAm4eJJk+erMEZV8U4VwRnbFXw7uXrhCYGJkuXLp2eMxq34A0NN+8lEhNhtIcpevvC0/2iCRelJm5hceoSFGYBMLPy22+/6edY60XmN9aDTYPXcsaMGeWDDz7QJTInvJbDCQN1PIOtWdiqgABdrFgxcQqsVaNrDy40MC349ddfa1LLV199pdOIyGQ3Cf6s9u3bp6MQzLxgXQ9r7hiJYCofU7ImwmsDa+oYjdpZydi+gsxwXCShe5JpnLgE1bdvX+2wh3N0n40bP368BsNPP/1UTLJnzx59HeP1vH79etdr2UkXoU7GQB1DuHKPLkwVmgb/3RhNOyXg2ZDw1rx5c73AwLkeOHBAp2fxxoZlBtxMhed8x44deq5z5swxOpkM08SYzrx8+bJuFYLdu3dL5syZ5aeffjJyD35kS1C4sFu2bJmRS1AYneLCAhdG7ubNm6fBG61yTYbAjdkA01/P4YL7qGMIU2lYS3rU9Q2+x8QXL5KC7ICHRJA7d+7o8evXr8uQIUOMDXjI6sU6JJLGsLXMhuQhfM00eG4x+sANF0ZY2y1SpIi+CWMkYipctOFiFG/AeDPGdjgk8iGgeBc/MQWeT0xzo1iI3XMY07MmL0GhYpavDPqSJUvKP//8I6bB+x3Wp91f06iohsGIya/ncMERdSymYKPLxHVfjJIwtYaAh+QsvBljZIo/wtq1a+s6sIlQzhKjaBRscT9vzAog6xQFZkySOHFifa7tvdMYpboXuKDAwv8/LjAuXLigIzx33klmJsAFGy58MP3trlu3brqmjrwXkyBhDFvfsFxmT3ljpsJJRWacjCPqGHIPvkOHDtUpQdSJdYe9yCgm8vHHH4tpMPJA0PCGIIK1SFNlyZJFiy0gULvDlb13hnKoYSYFMxd4I3NiRiySm7D9xlfQw9qqaZYvX64Xnpiu9x53mDqzZSeTof50uXLl9HNsfcN0PX4X7HaweQfzUBXwwes5su2RFFwM1AHIoPb27LPPSuPGjY0M1E4KeO6QfNWlSxe9CMKbL7LtsQ6JEUifPn3EJCgMgipqmIZ1WqCeMmWKvPvuu1ojGa8V9y1D+NjEQI3RKcpE4txw4ewE2BKJGgGA7YeA5xw3fM1mypYt5ADYWP0tBELWtysMJE2aVPs5ezt69Kh+zUTolV2oUCHtlZwqVSpr/fr11uzZs7Vt3bhx4yxTPXjwwBo0aJC2p0OLQNzQxrB3796WiUqWLGmtWrXKcppcuXJpK0AnwesY7SIpeNDGd8CAAdp7Gm04cUPvcrS8dG/xS8HBQO0H9Bf+6quvHjo+a9YsK0+ePJaJnBbwvN25c8fav3+/9vz+888/LVMtW7bMKl68uPX9999rH9zr16973EwOerjQdJJWrVpZU6dODfVphLUePXroxfyECROsPXv26C0iIkKP9erVK9SnF/aYTOYH9GTFbcSIEdr3FlavXq0lGFFnGKUNTXX37l2dAkeCCJKxUJGKAse9vrT79CX+3ExeN0Up2dKlSxtVoS46ZS0x9Y0tT8is985O79y5c8jOLVw4vfqb03GN2g/du3fXBBa8UBH47CpJWJs2OUgDChYgQFNwIBnLifLnz69r/igS4pSgh73HSMrC3x62Dnmvq5t4zk6DEr0FCxZ86DiOmVa+NxxxRB0AGJUicQh7TlEG0LR2kUTR5cRmEUh6QzDu0aOHMZ2ywo0Tq7+FEwZqoiDBdjdswbGLcGA3ALbycT914OuqI1jky5cv1KcStpzcgCgcMFATBQHaGdasWVNnWdA6EhBMUMwC07T21hwTYM/uwIEDJUWKFB77d32NqNHz2TQo4IP1aXR4ouDA/m4U8fHVgAiV1BDAKXgYqImCACMMrPdiXzLe4ABvaOiMhOljNOkwBZqELF68WKtM4eOoAvV///tfMQ2mvWfNmqVVs1DS0ntd3YSCIU6H2gBo1uLdvQ45OjhmanJkuGCgJgoCjKRRltU7AQdlUFHjGZnKFBhOvLhwmsjazKKkMpJSb968GbJziw+Y9U0UBCi1iOlC70CNNT3UKqfAcWqGvRPYSyF2VTrU3LdhFI2yp2hURMHFQE0UBI0aNdI9ySNHjpQKFSrosY0bN+qWPu/WhkSmwqyQe391bOu04WMsN6CMLwUXp76JAgTdmwoXLqzThNhXj6CMIhF220KsnaKO9rBhw7iFjxwFrU7Hjh3LphwhwkBNFISEGzQ4QZY31qrtpgvYPuQ+dUhEFB2c+iYKEGRNHz9+XAP1iRMntEUkAjMqfBERxRYDNVGAvP7661KlShXJmjWrJt8guxujbF9MrPBFRGZioCYKkC+++EJee+01bXaCvb3ooc0MbyLyF9eoiYKUfIO6yAzUROQvBmoiIiKDsdUMERGRwRioiYiIDMZATUREZDAGaiIiIoMxUBMRERmMgZqIiMhgDNREREQGY6AmIiISc/0/OI2lmqys7RMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting\n",
        "x = torch.arange(len(vocab))\n",
        "bar_width = 0.15\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 3))\n",
        "for i, T in enumerate(temperatures):\n",
        "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
        "\n",
        "ax.set_ylabel('Probability')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"temperature-plot.pdf\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d750e989-842a-4cfa-a44b-cf44d6e49163",
      "metadata": {
        "id": "d750e989-842a-4cfa-a44b-cf44d6e49163"
      },
      "source": [
        "- We can see that the rescaling via temperature 0.1 results in a sharper distribution, approaching `torch.argmax`, such that the most likely word is almost always selected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
      "metadata": {
        "id": "e4600713-c51e-4f53-bf58-040a6eb362b8",
        "outputId": "c9e39fbb-bb29-432b-9ab0-4dce9e1d6eb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 x closer\n",
            "0 x every\n",
            "0 x effort\n",
            "985 x forward\n",
            "0 x inches\n",
            "0 x moves\n",
            "0 x pizza\n",
            "15 x toward\n",
            "0 x you\n"
          ]
        }
      ],
      "source": [
        "print_sampled_tokens(scaled_probas[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b",
      "metadata": {
        "id": "526e93cb-8e2a-42a1-b1ba-4fd5fe64c26b"
      },
      "source": [
        "- The rescaled probabilities via temperature 5 are more uniformly distributed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
      "metadata": {
        "id": "9dfb48f0-bc3f-46a5-9844-33b6c9b0f4df",
        "outputId": "a8ef4702-f85e-4437-81ac-ce0b6990bee4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "165 x closer\n",
            "75 x every\n",
            "42 x effort\n",
            "239 x forward\n",
            "71 x inches\n",
            "46 x moves\n",
            "32 x pizza\n",
            "227 x toward\n",
            "103 x you\n"
          ]
        }
      ],
      "source": [
        "print_sampled_tokens(scaled_probas[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7",
      "metadata": {
        "id": "0c83f0c4-3774-4375-ad7f-96440ba5fef7"
      },
      "source": [
        "- Assuming an LLM input \"every effort moves you\", using the approach above can sometimes result in nonsensical texts, such as \"every effort moves you pizza\", 3.2% of the time (32 out of 1000 times)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7",
      "metadata": {
        "id": "c6e4873e-07e4-4abb-85df-bdaedcc1a6f7"
      },
      "source": [
        "### 5.3.2 Top-k sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df",
      "metadata": {
        "id": "6d4da95a-8bb2-4f69-a9b0-a643531db5df"
      },
      "source": [
        "- To be able to use higher temperatures to increase output diversity and to reduce the probability of nonsensical sentences, we can restrict the sampled tokens to the top-k most likely tokens:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17",
      "metadata": {
        "id": "7ae6fffd-2730-4abe-a2d3-781fc4836f17"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=500px>\n",
        "\n",
        "- (Please note that the numbers in this figure are truncated to two\n",
        "digits after the decimal point to reduce visual clutter. The values in the Softmax row should add up to 1.0.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c",
      "metadata": {
        "id": "0ba12da5-6ff1-4008-91b8-d2d537cbc14c"
      },
      "source": [
        "- In code, we can implement this as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
      "metadata": {
        "id": "2a7f908a-e9ec-446a-b407-fb6dbf05c806",
        "outputId": "00f5a371-b41f-4348-f00d-39b7e354d4ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
            "Top positions: tensor([3, 7, 0])\n"
          ]
        }
      ],
      "source": [
        "top_k = 3\n",
        "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
        "\n",
        "print(\"Top logits:\", top_logits)\n",
        "print(\"Top positions:\", top_pos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
      "metadata": {
        "id": "753865ed-79c5-48b1-b9f2-ccb132ff1d2f",
        "outputId": "26880cce-a388-4a72-965c-0d69405fc840"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
          ]
        }
      ],
      "source": [
        "new_logits = torch.where(\n",
        "    condition=next_token_logits < top_logits[-1],\n",
        "    input=torch.tensor(float(\"-inf\")),\n",
        "    other=next_token_logits\n",
        ")\n",
        "\n",
        "print(new_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00",
      "metadata": {
        "id": "dfa6fa49-6e99-459d-a517-d7d0f51c4f00"
      },
      "source": [
        "> NOTE:  \n",
        ">\n",
        ">  An alternative, slightly more efficient implementation of the previous code cell is the following:\n",
        ">\n",
        "> ```python\n",
        "> new_logits = torch.full_like( # create tensor containing -inf values\n",
        ">    next_token_logits, -torch.inf\n",
        ">)   \n",
        "> new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor\n",
        "> ```\n",
        "> <br>\n",
        "> For more details, see https://github.com/rasbt/LLMs-from-scratch/discussions/326\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
      "metadata": {
        "id": "4844f000-c329-4e7e-aa89-16a2c4ebee43",
        "outputId": "8068117d-05bc-4d5e-b1e0-49557a8a23ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
          ]
        }
      ],
      "source": [
        "topk_probas = torch.softmax(new_logits, dim=0)\n",
        "print(topk_probas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56056503-a15d-4315-a3ff-46647a4c7c45",
      "metadata": {
        "id": "56056503-a15d-4315-a3ff-46647a4c7c45"
      },
      "source": [
        "### 5.3.3 Modifying the text generation function"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34770423-473d-46f6-a5fa-6b2979564d26",
      "metadata": {
        "id": "34770423-473d-46f6-a5fa-6b2979564d26"
      },
      "source": [
        "- The previous two subsections introduced temperature sampling and top-k sampling\n",
        "- Let's use these two concepts to modify the `generate_simple` function we used to generate text via the LLM earlier, creating a new `generate` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e318891-bcc0-4d71-b147-33ce55febfa3",
      "metadata": {
        "id": "8e318891-bcc0-4d71-b147-33ce55febfa3"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # New: Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            # Keep only top_k values\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        # New: Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "\n",
        "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
        "            break\n",
        "\n",
        "        # Same as before: append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
      "metadata": {
        "id": "aa2a0d7d-0457-42d1-ab9d-bd67683e7ed8",
        "outputId": "1ce65654-994f-45a1-ba56-50d7e1060a18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you stand to work on surprise, a one of us had gone with random-\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "    top_k=25,\n",
        "    temperature=1.4\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b",
      "metadata": {
        "id": "4e2002ca-f4c1-48af-9e0a-88bfc163ba0b"
      },
      "source": [
        "## 5.4 Loading and saving model weights in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fc52676-f026-4566-a226-2a90269f9d53",
      "metadata": {
        "id": "0fc52676-f026-4566-a226-2a90269f9d53"
      },
      "source": [
        "- Training LLMs is computationally expensive, so it's crucial to be able to save and load LLM weights\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model-3.webp\" width=400px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82",
      "metadata": {
        "id": "10e4c7f9-592f-43d6-a00e-598fa01dfb82"
      },
      "source": [
        "- The recommended way in PyTorch is to save the model weights, the so-called `state_dict` via by applying the `torch.save` function to the `.state_dict()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47",
      "metadata": {
        "id": "3d67d869-ac04-4382-bcfb-c96d1ca80d47"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e",
      "metadata": {
        "id": "90e889e0-07bf-43e5-8f92-5c5c7aeaad9e"
      },
      "source": [
        "- Then we can load the model weights into a new `GPTModel` model instance as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d57d914-60a3-47f1-b499-5352f4c457cb",
      "metadata": {
        "id": "9d57d914-60a3-47f1-b499-5352f4c457cb"
      },
      "outputs": [],
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1",
      "metadata": {
        "id": "caa81aec-9c72-4f46-8ae2-4a4fde3edbc1"
      },
      "source": [
        "- It's common to train LLMs with adaptive optimizers like Adam or AdamW instead of regular SGD\n",
        "- These adaptive optimizers store additional parameters for each model weight, so it makes sense to save them as well in case we plan to continue the pretraining later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532",
      "metadata": {
        "id": "bbd175bb-edf4-450e-a6de-d3e8913c6532"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0c7295-c822-43bf-9286-c45abc542868",
      "metadata": {
        "id": "8a0c7295-c822-43bf-9286-c45abc542868"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4194350e-0409-4a63-8ffd-d3a896509032",
      "metadata": {
        "id": "4194350e-0409-4a63-8ffd-d3a896509032"
      },
      "source": [
        "## 5.5 Loading pretrained weights from OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec",
      "metadata": {
        "id": "83eb6c38-7278-40e0-bd9f-8a2b1feac3ec"
      },
      "source": [
        "- Previously, we only trained a small GPT-2 model using a very small short-story book for educational purposes\n",
        "- Interested readers can also find a longer pretraining run on the complete Project Gutenberg book corpus in [../03_bonus_pretraining_on_gutenberg](../03_bonus_pretraining_on_gutenberg)\n",
        "- Fortunately, we don't have to spend tens to hundreds of thousands of dollars to pretrain the model on a large pretraining corpus but can load the pretrained weights provided by OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "127ddbdb-3878-4669-9a39-d231fbdfb834",
      "metadata": {
        "id": "127ddbdb-3878-4669-9a39-d231fbdfb834"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "âš ï¸ **Note: Some users may encounter issues in this section due to TensorFlow compatibility problems, particularly on certain Windows systems. TensorFlow is required here only to load the original OpenAI GPT-2 weight files, which we then convert to PyTorch.\n",
        "If you're running into TensorFlow-related issues, you can use the alternative code below instead of the remaining code in this section.\n",
        "This alternative is based on pre-converted PyTorch weights, created using the same conversion process described in the previous section. For details, refer to the notebook:\n",
        "[../02_alternative_weight_loading/weight-loading-pytorch.ipynb](../02_alternative_weight_loading/weight-loading-pytorch.ipynb) notebook.**\n",
        "\n",
        "```python\n",
        "file_name = \"gpt2-small-124M.pth\"\n",
        "# file_name = \"gpt2-medium-355M.pth\"\n",
        "# file_name = \"gpt2-large-774M.pth\"\n",
        "# file_name = \"gpt2-xl-1558M.pth\"\n",
        "\n",
        "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
        "\n",
        "if not os.path.exists(file_name):\n",
        "    urllib.request.urlretrieve(url, file_name)\n",
        "    print(f\"Downloaded to {file_name}\")\n",
        "\n",
        "gpt = GPTModel(BASE_CONFIG)\n",
        "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
        "gpt.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt.to(device);\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75cab892-a165-4f43-9601-f517bc212ab6",
      "metadata": {
        "id": "75cab892-a165-4f43-9601-f517bc212ab6"
      },
      "source": [
        "- First, some boilerplate code to download the files from OpenAI and load the weights into Python\n",
        "- Since OpenAI used [TensorFlow](https://www.tensorflow.org/), we will have to install and use TensorFlow for loading the weights; [tqdm](https://github.com/tqdm/tqdm) is a progress bar library\n",
        "- Uncomment and run the next cell to install the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8",
      "metadata": {
        "id": "fb9fdf02-972a-444e-bf65-8ffcaaf30ce8"
      },
      "outputs": [],
      "source": [
        "# pip install tensorflow tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
      "metadata": {
        "id": "a0747edc-559c-44ef-a93f-079d60227e3f",
        "outputId": "b202e1bc-afed-4c24-872b-2d705810bd2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "tqdm version: 4.67.1\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
        "print(\"tqdm version:\", version(\"tqdm\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed",
      "metadata": {
        "id": "c5bc89eb-4d39-4287-9b0c-e459ebe7f5ed"
      },
      "outputs": [],
      "source": [
        "# Relative import from the gpt_download.py contained in this folder\n",
        "\n",
        "from gpt_download import download_and_load_gpt2\n",
        "# Alternatively:\n",
        "# from llms_from_scratch.ch05 import download_and_load_gpt2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc",
      "metadata": {
        "id": "ff76a736-6f9f-4328-872e-f89a7b70a2cc"
      },
      "source": [
        "---\n",
        "\n",
        "**Note**\n",
        "\n",
        "- In very rare cases, the code cell above may result in a `zsh: illegal hardware instruction python` error, which could be due to a TensorFlow installation issue on your machine\n",
        "- A reader found that installing TensorFlow via `conda` solved the issue in this specific case, as mentioned [here](https://github.com/rasbt/LLMs-from-scratch/discussions/273#discussioncomment-12367888)\n",
        "- You can find more instructions in this supplementary [Python setup tutorial](https://github.com/rasbt/LLMs-from-scratch/tree/main/setup/01_optional-python-setup-preferences#option-2-using-conda)\n",
        "\n",
        "---\n",
        "\n",
        "- We can then download the model weights for the 124 million parameter model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
      "metadata": {
        "id": "76271dd7-108d-4f5b-9c01-6ae0aac4b395",
        "outputId": "e4eb3d2f-194d-4e44-ca7d-966103e707d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 63.1kiB/s]\n",
            "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:00<00:00, 4.69MiB/s]\n",
            "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 59.7kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [01:09<00:00, 7.15MiB/s]\n",
            "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 2.32MiB/s]\n",
            "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:00<00:00, 2.19MiB/s]\n",
            "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 3.47MiB/s]\n"
          ]
        }
      ],
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
      "metadata": {
        "id": "b1a31951-d971-4a6e-9c43-11ee1168ec6a",
        "outputId": "23893622-7ef2-4383-8b17-3cce8d2485f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
          ]
        }
      ],
      "source": [
        "print(\"Settings:\", settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
      "metadata": {
        "id": "857c8331-130e-46ba-921d-fa35d7a73cfe",
        "outputId": "dc6b1810-ac3a-462c-d3ff-2b3e6dddd092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
          ]
        }
      ],
      "source": [
        "print(\"Parameter dictionary keys:\", params.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
      "metadata": {
        "id": "c48dac94-8562-4a66-84ef-46c613cdc4cd",
        "outputId": "07e33258-48fe-4763-8038-38ab31f343cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
            "   0.04531523]\n",
            " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
            "   0.04318958]\n",
            " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
            "  -0.08785918]\n",
            " ...\n",
            " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
            "  -0.06952604]\n",
            " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
            "  -0.02245961]\n",
            " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
            "   0.12067825]]\n",
            "Token embedding weight tensor dimensions: (50257, 768)\n"
          ]
        }
      ],
      "source": [
        "print(params[\"wte\"])\n",
        "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466e100c-294e-4afc-a70a-2f398ac4c104",
      "metadata": {
        "id": "466e100c-294e-4afc-a70a-2f398ac4c104"
      },
      "source": [
        "- Alternatively, \"355M\", \"774M\", and \"1558M\" are also supported `model_size` arguments\n",
        "- The difference between these differently sized models is summarized in the figure below:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20f19d32-5aae-4176-9f86-f391672c8f0d",
      "metadata": {
        "id": "20f19d32-5aae-4176-9f86-f391672c8f0d"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=500px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41",
      "metadata": {
        "id": "ea6e5076-f08d-41fc-bd8b-1cfe53538f41"
      },
      "source": [
        "- Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our `GPTModel` instance\n",
        "- First, we initialize a new GPTModel instance\n",
        "- Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting `qkv_bias` to `True` in our implementation, too\n",
        "- We are also using the `1024` token context length that was used by the original GPT-2 model(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fef90dd-0654-4667-844f-08e28339ef7d",
      "metadata": {
        "id": "9fef90dd-0654-4667-844f-08e28339ef7d"
      },
      "outputs": [],
      "source": [
        "# Define model configurations in a dictionary for compactness\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])\n",
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "272f29ac-8342-4b3d-a57d-9b0166ced314",
      "metadata": {
        "id": "272f29ac-8342-4b3d-a57d-9b0166ced314"
      },
      "source": [
        "- The next task is to assign the OpenAI weights to the corresponding weight tensors in our `GPTModel` instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9a92229-c002-49a6-8cfb-248297ad8296",
      "metadata": {
        "id": "f9a92229-c002-49a6-8cfb-248297ad8296"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9",
      "metadata": {
        "id": "f22d5d95-ca5a-425c-a9ec-fc432a12d4e9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
        "\n",
        "\n",
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7472cb-54dc-4311-96d8-b2694f885cee",
      "metadata": {
        "id": "4f7472cb-54dc-4311-96d8-b2694f885cee"
      },
      "source": [
        "- If the model is loaded correctly, we can use it to generate new text using our previous `generate` function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
      "metadata": {
        "id": "1f690253-f845-4347-b7b6-43fabbd2affa",
        "outputId": "6925c311-be44-444d-9a8e-7580b30b17c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output text:\n",
            " Every effort moves you toward finding an ideal new way to practice something!\n",
            "\n",
            "What makes us want to be on top of that?\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d079f98-a7c4-462e-8416-5a64f670861c",
      "metadata": {
        "id": "6d079f98-a7c4-462e-8416-5a64f670861c"
      },
      "source": [
        "- We know that we loaded the model weights correctly because the model can generate coherent text; if we made even a small mistake, the model would not be able to do that"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44",
      "metadata": {
        "id": "28493b9b-a1ae-4f31-87bc-c10ee4447f44"
      },
      "source": [
        "- For an alternative way to load the weights from the Hugging Face Hub, see [../02_alternative_weight_loading](../02_alternative_weight_loading)\n",
        "- If you are interested in seeing how the GPT architecture compares to the Llama architecture (a popular LLM developed by Meta AI), see the bonus content at [../07_gpt_to_llama](../07_gpt_to_llama)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4",
      "metadata": {
        "id": "f2a66474-230d-4180-a8ff-843e04f1f1c4"
      },
      "source": [
        "## Summary and takeaways"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7ed189-a633-458c-bf12-4f70b42684b8",
      "metadata": {
        "id": "fc7ed189-a633-458c-bf12-4f70b42684b8"
      },
      "source": [
        "- See the [./gpt_train.py](./gpt_train.py) script, a self-contained script for training\n",
        "- The [./gpt_generate.py](./gpt_generate.py) script loads pretrained weights from OpenAI and generates text based on a prompt\n",
        "- You can find the exercise solutions in [./exercise-solutions.ipynb](./exercise-solutions.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}